{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('u.data', sep='\\t', names=['user', 'item', 'rate', 'time'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mean = np.mean(df.rate)\n",
    "print(\"Global mean:\", global_mean)\n",
    "\n",
    "unique_users = pd.unique(df.user)\n",
    "unique_items = pd.unique(df.item)\n",
    "\n",
    "user_biases = np.zeros((len(unique_users), 1))\n",
    "for i, user in enumerate(unique_users):\n",
    "    user_biases[i] = np.mean(df.loc[df['user'] == user].rate) - global_mean\n",
    "\n",
    "item_biases = np.zeros((1, len(unique_items)))\n",
    "for i, item in enumerate(unique_items):\n",
    "    item_biases[0:i] = np.mean(df.loc[df['item'] == item].rate) - global_mean\n",
    "    \n",
    "bias_users = tf.Variable(initial_value=user_biases, dtype=tf.float32)\n",
    "bias_items = tf.Variable(initial_value=item_biases, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "feature_len = tf.placeholder(tf.int32)\n",
    "U = tf.Variable(initial_value=tf.truncated_normal([len(unique_users), feature_len]), name='users', validate_shape=False)\n",
    "P = tf.Variable(initial_value=tf.truncated_normal([feature_len, len(unique_items)]), name='items', validate_shape=False)\n",
    "\n",
    "# To the user matrix we add a bias column holding the bias of each user,\n",
    "# and another column of 1s to multiply the item bias by.\n",
    "U_plus_bias = tf.concat(axis=1, values = [U, bias_users, tf.ones((len(unique_users),1), dtype=tf.float32)])\n",
    "\n",
    "# To the item matrix we add a row of 1s to multiply the user bias by, and\n",
    "# a bias row holding the bias of each item.\n",
    "P_plus_bias = tf.concat(axis=0, values = [P, tf.ones((1, len(unique_items)), dtype=tf.float32), bias_items])\n",
    "\n",
    "result = tf.matmul(U, P)\n",
    "result_flatten = tf.reshape(result, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.3)\n",
    "\n",
    "user_indices_train = [x-1 for x in df_train.user.values]\n",
    "item_indices_train = [x-1 for x in df_train.item.values]\n",
    "\n",
    "user_indices_test = [x-1 for x in df_test.user.values]\n",
    "item_indices_test = [x-1 for x in df_test.item.values]\n",
    "\n",
    "result_flatten_train = tf.gather(result_flatten, user_indices_train * tf.shape(result)[1] + item_indices_train)\n",
    "result_flatten_test = tf.gather(result_flatten, user_indices_test * tf.shape(result)[1] + item_indices_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_squared = tf.square(tf.subtract(result_flatten_train, df_train.rate.values))\n",
    "base_cost = tf.reduce_sum(diff_squared, name=\"sum_squared_error\")\n",
    "\n",
    "lambda_norms = tf.constant(.001, dtype=tf.float32)\n",
    "norm_sums = tf.add(tf.reduce_sum(tf.square(U_plus_bias)), tf.reduce_sum(tf.square(P_plus_bias)))\n",
    "norms_regularized = tf.multiply(lambda_norms, norm_sums)\n",
    "\n",
    "lambda_biases = tf.constant(.01, dtype=tf.float32)\n",
    "biases_sums = tf.add(tf.reduce_sum(tf.square(bias_users)), tf.reduce_sum(tf.square(bias_items)))\n",
    "biases_regularized = tf.multiply(lambda_biases, biases_sums)\n",
    "\n",
    "norm_biases_sums = tf.add(norms_regularized, biases_regularized)\n",
    "base_cost_regularized = tf.add(base_cost, norm_biases_sums)\n",
    "\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(.001, global_step, 10000, 0.96, staircase=True)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_step = optimizer.minimize(base_cost_regularized, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training accuracy\n",
    "diff_op_train = tf.subtract(result_flatten_train, df_train.rate.values, name='train_diff')\n",
    "good_val_train = tf.less(tf.abs(diff_op_train), 0.5)\n",
    "training_accuracy = tf.reduce_sum(tf.cast(good_val_train, tf.float32)) / tf.size(good_val_train, out_type = tf.float32)\n",
    "\n",
    "#test accuracy\n",
    "diff_op_test = tf.subtract(result_flatten_test, df_test.rate.values, name='test_diff')\n",
    "good_val_test = tf.less(tf.abs(diff_op_test), 0.5)\n",
    "test_accuracy = tf.reduce_sum(tf.cast(good_val_test, tf.float32)) / tf.size(good_val_test, out_type = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init, feed_dict={feature_len:10})\n",
    "\n",
    "iterations = 100000\n",
    "for i in range(iterations + 1):\n",
    "    if i % 10000 == 0:\n",
    "        print(\"Iter:\", i, \" Train_acc:\", sess.run(training_accuracy), \" Test_acc:\", sess.run(test_accuracy))\n",
    "\n",
    "    sess.run(training_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
