{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('u.data', sep='\\t', names=['user', 'item', 'rate', 'time'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(pd.unique(df.user))\n",
    "num_items = len(pd.unique(df.item))\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.1)\n",
    "\n",
    "user_indices_train = [x-1 for x in df_train.user.values]\n",
    "item_indices_train = [x-1 for x in df_train.item.values]\n",
    "\n",
    "user_indices_test = [x-1 for x in df_test.user.values]\n",
    "item_indices_test = [x-1 for x in df_test.item.values]\n",
    "\n",
    "y = tf.dtypes.cast(df_train.rate.values, tf.float32)\n",
    "y_test = tf.dtypes.cast(df_test.rate.values, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_len = 10\n",
    "\n",
    "U = tf.Variable(tf.random_normal([num_users, feature_len], mean=0.08, stddev=0.03), dtype=tf.float32)\n",
    "V = tf.Variable(tf.random_normal([num_items, feature_len], mean=0.08, stddev=0.03), dtype=tf.float32)\n",
    "B_u = tf.Variable(tf.random_normal([num_users],  stddev=0.001))\n",
    "B_v = tf.Variable(tf.random_normal([num_items],  stddev=0.001))\n",
    "\n",
    "#for train set\n",
    "users_train = tf.nn.embedding_lookup(U ,user_indices_train)\n",
    "items_train = tf.nn.embedding_lookup(V, item_indices_train)\n",
    "bias_u_train = tf.nn.embedding_lookup(B_u ,user_indices_train)\n",
    "bias_v_train = tf.nn.embedding_lookup(B_v ,item_indices_train)\n",
    "\n",
    "#for test set\n",
    "users_test = tf.nn.embedding_lookup(U ,user_indices_test)\n",
    "items_test = tf.nn.embedding_lookup(V, item_indices_test)\n",
    "bias_u_test = tf.nn.embedding_lookup(B_u ,user_indices_test)\n",
    "bias_v_test = tf.nn.embedding_lookup(B_v ,item_indices_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rating, max_rating = 1, 5\n",
    "global_mean = np.mean(df.rate)\n",
    "\n",
    "#as we train model on droput distances\n",
    "#we need these two for accuracy mesurments\n",
    "distances_test = tf.clip_by_value( tf.reduce_sum( tf.square(users_test - items_test)  ,1) + bias_u_test + bias_v_test +   (max_rating - global_mean), min_rating, max_rating)\n",
    "distances_train = tf.clip_by_value( tf.reduce_sum( tf.square(users_train - items_train)  ,1) + bias_u_train + bias_v_train +   (max_rating - global_mean), min_rating, max_rating)\n",
    "\n",
    "dropout_distances = tf.clip_by_value(tf.reduce_sum( tf.nn.dropout(tf.square(users_train - items_train), 0.95) ,1)  + bias_u_train + bias_v_train +   (max_rating - global_mean)  , min_rating, max_rating)\n",
    "loss = tf.reduce_sum( (1+0.2*tf.abs(y-(max_rating )/2)) * tf.square((max_rating - y) - dropout_distances) ) + 0.01 * (tf.norm(B_u) + tf.norm(B_v) )\n",
    "optimizer = tf.train.AdagradOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training accuracy\n",
    "diff_op_train = tf.subtract((max_rating - distances_train), y, name='train_diff')\n",
    "good_val_train = tf.less(tf.abs(diff_op_train), 0.5)\n",
    "training_accuracy = tf.reduce_sum(tf.cast(good_val_train, tf.float32)) / tf.size(good_val_train, out_type = tf.float32)\n",
    "\n",
    "#test accuracy\n",
    "diff_op_test = tf.subtract((max_rating - distances_test), y_test, name='test_diff')\n",
    "good_val_test = tf.less(tf.abs(diff_op_test), 0.5)\n",
    "test_accuracy = tf.reduce_sum(tf.cast(good_val_test, tf.float32)) / tf.size(good_val_test, out_type = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "iterations = 100000\n",
    "for i in range(iterations + 1):\n",
    "    sess.run((optimizer, loss))\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        print(\"Iter:\", i, \" Train_acc:\", sess.run(training_accuracy), \" Test_acc:\", sess.run(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
